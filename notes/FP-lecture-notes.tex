\documentclass[a4paper,oneside]{memoir}


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{lmodern}



%\usepackage[czech]{babel}
\usepackage{amsmath,amssymb,mathtools,amsthm,bm}

\usepackage{xspace}


\usepackage{lipsum}





\usepackage{qtree}
\usepackage[usenames,dvipsnames,table]{xcolor}
\usepackage{amsfonts}
% \usepackage{amsmath}
\usepackage{graphicx}

\usepackage[vlined,ruled,norelsize]{algorithm2e}




\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}





%\usepackage{enumitem}

\title{Some FP lecture notes (v0.3)}

\author{Tomáš Křen}

\hyphenation{vě-dec-ká}

\begin{document}

\theoremstyle{plain} 
\newtheorem{theorem}{Theorem} 
\newtheorem{proposition}{Proposition} 
\newtheorem{lemma}{Lemma} 
\newtheorem{preLemma}{Pre-Lemma} 
\newtheorem*{corollary}{Corollary}

\theoremstyle{definition} 
\newtheorem*{definition}{Definition} 
\newtheorem*{preDefinition}{Pre-Definition} 
\newtheorem{conjecture}{Conjecture}
\newtheorem*{example}{Example} 

\theoremstyle{remark} 
\newtheorem*{remark}{Remark} 
\newtheorem*{note}{Note} 
\newtheorem{case}{Case}

\frontmatter
\mainmatter
\maketitle

%\renewcommand{\chaptername}{Akt}

\tableofcontents*
%\clearpage

\newcommand{\red}[1]{{\color{red} #1}}



\newcommand{\sigmaPr}{\sigma^\prime}
\newcommand{\tauPr}{\tau^\prime}
\newcommand{\xPr}{x^\prime}
\newcommand{\nPr}{n^\prime}
\newcommand{\nPrr}{n^{\prime\prime}}
\newcommand{\nPrrr}{n^{\prime\prime\prime}}
\newcommand{\tausPr}{\tau_s^\prime}
\newcommand{\s}{\sigma}
\newcommand{\Th}{\theta}
\newcommand{\sPr}{\sigmaPr}
\newcommand{\thPr}{\theta^\prime}



\newcommand{\then}{\Rightarrow}
\newcommand{\E}[2]{(\exists #1)\ #2}
\newcommand{\A}[2]{(\forall #1)\ #2}
\newcommand{\Ain}[3]{(\forall #1 \in #2)\ #3}


\newcommand{\op}{\operatorname}

\newcommand{\ar}{\rightarrow}
\newcommand{\ap}[2]{(#1\,#2)}
\newcommand{\defi}{\coloneqq}
\newcommand{\defe}{\mathrel{\vcentcolon\equiv}}

\newcommand{\unaRule}[2]{\dfrac{#1}{#2}}
\newcommand{\binRule}[3]{\dfrac{#1 ~ ~ ~ ~ ~ ~ ~ #2}{#3}}
\newcommand{\triRule}[4]{\dfrac{#1 ~ ~ ~ ~ ~ ~ ~ #2 ~ ~ ~ ~ ~ ~ ~ #3}{#4}}
\newcommand{\isSub}[1]{#1\ \mathit{substitution}}
\newcommand{\MGU}[2]{\op{MGU}(#1,#2)}
\newcommand{\mgu}[1]{\op{MGU}(#1)}

\newcommand{\AX}{\textit{AX}\xspace}
\newcommand{\subAx}{\textit{SUB-AX}\xspace}
\newcommand{\mguMp}{\textit{MGU-MP}\xspace}
\newcommand{\abs}[1]{\lvert #1 \rvert}

\newcommand{\Pseudokod}[4]{
	\begin{figure}[!t]
	\removelatexerror
	\begin{algorithm}[H]
		\caption{\label{#4}#1}
		\DontPrintSemicolon
		\SetKwProg{Fn}{function}{}{}
		\Fn{#2}{#3}
	\end{algorithm}
	\end{figure}
}

\makeatletter
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother

\newcommand{\la}{\leftarrow\xspace}












\newcommand{\inhab}[1]{\op{I}(#1)}

\newcommand{\tord}{\preccurlyeq}
\newcommand{\stord}{\prec}
\newcommand{\ordt}{\tord_\tau}
\newcommand{\tek}{\sim}
\newcommand{\ntek}{\nsim}
\newcommand{\ekt}{\tek_\tau}
\newcommand{\nekt}{\ntek_\tau}
\newcommand{\nsucct}{\nsucc_\tau}

\newcommand{\MGI}[1]{\op{MGI}(#1)}
\newcommand{\MGIt}{\MGI{\tau}}
\newcommand{\It}{\op{I}(\tau)}

\newcommand{\ids}{\sigma_{\op{id}}}

\newcommand{\U}[2]{\op{U}(#1,#2)}
\newcommand{\Utt}{\U{\tau}{\tauPr}}
\newcommand{\MGUtt}{\MGU{\tau}{\tauPr}}

\newcommand{\e}[2]{\op{E}_{#1}(#2)}
\newcommand{\restrict}[2]{{#1}_{\mid #2}}
\newcommand{\fresh}[2]{\op{fresh}_{#1}(#2)}
\newcommand{\newVar}[1]{\op{newVar}(#1)}
\newcommand{\Ss}[1]{\op{ss}(#1)}
\newcommand{\TS}[2]{\op{ts}_{#1}(#2)}
\newcommand{\ts}[2]{\op{ts}_{#1}(#2)}
\newcommand{\TSij}[3]{\op{ts}_{#1,#2}(#3)}
\newcommand{\trees}[2]{\op{trees}_{#1}(#2)}
\newcommand{\FX}{\ap{F}{X}}
\newcommand{\sF}{\s_{F}}
\newcommand{\sX}{\s_{X}}
\newcommand{\vars}[1]{\op{vars}(#1)}
\newcommand{\dom}[1]{\op{dom}(#1)}
\newcommand{\IH}{induction hypothesis\xspace}
\newcommand{\discup}{~\mathbin{\dot{\cup}}~}






\chapter{Hindley-Milner type system}

\red{\textbf{Still work in progress... but the sections about Hindley-Milner algorithm W are almost OK now.}}

\newcommand{\letin}[3]{\texttt{let} \, #1 = #2 \, \texttt{in} \, #3}
\newcommand{\W}{\op{\textbf{W}}}
\newcommand{\Mgu}{\op{\textbf{MGU}}}
\newcommand{\where}{\op{\textbf{where~}}}
\newcommand{\SPr}{S^\prime}


\section{Introduction}

\red{Why Hindley-Milner (= simplified system F capable of type inference in curry style)}


\section{Language of type expressions}

\red{Explain simple types and type schemes.}

\section{Type substitutions}

\red{definition} ; \red{informally explain: makes a type more specific} ; \red{as function} ; \red{can be composed by $\circ$}

\section{Contexts}

\begin{definition}
A $\mathit{term:type}$ statement $\mathit{M}:\mathit{\tau}$ states that (program) term $M$ has type $\tau$.   
A \textit{declaration} is a statement $s : \tau$ where $s$ is a term symbol and $\tau$ is a type.
A \textit{context} is set of declarations with distinct term symbols.\footnote{Interestingly, the definition of a \textit{context} and definition of a \textit{substitution} are almost the same. The difference is that "keys" in a context are term symbols/variables, whereas substitution "keys" are type variables. Maybe this fact could be utilized in an interesting way...}
\end{definition}


\red{building symbols}

\red{def $\Gamma_x$} ; \red{def $\overline{\Gamma}(\tau)$}




\section{Inference rules}

\texttt{TAUT} rule:

$$\unaRule{(x : \sigma) \in \Gamma}{ \Gamma \vdash x : \sigma}$$

\texttt{COMB} rule:

$$\binRule{\Gamma \vdash e_1 : \tau_1 \ar \tau_2}{\Gamma \vdash e_2 : \tau_1}
{\Gamma \vdash (e_1~e_2) : \tau_2}$$

\texttt{ABS} rule:

$$\unaRule{\Gamma_x,x:\tau_1 \vdash e : \tau_2}
{\Gamma \vdash (\lambda x . e) :  \tau_1 \ar \tau_2}$$

\texttt{LET} rule:

$$\binRule{\Gamma \vdash e_1 : \sigma}{\Gamma_x,x:\sigma \vdash e_2 : \tau}
{\Gamma \vdash (\letin{x}{e_1}{e_2}) :  \tau}$$

\texttt{INST} rule:

$$\binRule{\Gamma \vdash e : \sigma}{\sigma \sqsupseteq \sPr}
{\Gamma \vdash e : \sPr}$$

\texttt{GEN} rule:

$$\binRule{\Gamma \vdash e : \sigma}{\alpha \notin \op{FTV}(\Gamma)}
{\Gamma \vdash e : \forall \alpha . \sigma}$$

$\sqsupseteq$ rule:

$$\binRule{\beta_i \notin \op{FTV}(\forall \overline{\alpha}.\tau)}
{\tauPr = \{\overline{\alpha} \mapsto \overline{\tau}\}(\tau)}
{\forall \overline{\alpha}.\tau  ~ \sqsupseteq ~   \forall \overline{\beta}.\tauPr}$$

$\sqsupseteq$ rule, hopefully more readable:

$$\triRule{\beta_i \notin \op{FTV}(\forall \alpha_1\dots\alpha_n.\tau) \text{ for } i \in \{1,\dots,k\}}
{\tauPr = \{ \alpha_1 \mapsto \tau_1,  \dots, \alpha_n \mapsto \tau_n \}(\tau)}
{n,k \geq 0}
{\forall \alpha_1\dots\alpha_n.\tau  ~ \sqsupseteq ~   \forall \beta_1\dots\beta_k.\tauPr}$$



\section{Hindley-Milner algorithm W}

The Hindley-Milner algorithm $\W$ is used for type inference.
Loosely speaking, we give to $\W$ as an input 
a \textit{program expression} $e$ without type information 
and it returns a \textit{type} $\tau$ of that expression as a result, 
or it tells us that the expression cannot be typed correctly.

From this simplified point of view we may see the algorithm usage as:

(1) We have an expression $e$, for which we would like to know the type. 

So we run $\W$ on $e$ and we may either get as a result:

(2a) a type $\tau$, so we know that $e$ has type $\tau$,

(2b) or the \textit{fail result} $\bot$ (usually called \textit{bottom}), so we know there is a type error inside $e$.

~   

The first simplification of this description lies in that we have omitted 
the typing contexts (the "Gammas"). 
All the inference rules deal with \textit{judgments} of the form:

$$\Gamma \vdash e : \tau$$

And so does the $\W$ algorithm.
If $e$ is the top-level program expression,
we can think of a context $\Gamma$ as a collection of type information about the "library"
in which the program expression $e$ is written.
Or, if $e$ is some local sub-expression, then its $\Gamma$ contains also type information about
all the local variables defined in its scope.

We can think of a judgment of the form $\Gamma \vdash e : \tau$ as: 
\textit{From the building symbols described in the typing context $\Gamma$ we can build 
a well-typed program expression $e$ which has type $\tau$.}
Therefore it makes sense to provide a typing context $\Gamma$ to the $\W$ algorithm as another argument: $\W(\Gamma, e)$.

But $\W$ algorithm is even stronger: We may use libraries for which we do not know the proper typing information yet.

For example consider the following expression $e$:

$$ \lambda x . ((+~((+~x)~1))~x) $$

Or, in a more readable fashion, $e = \lambda x . (x+1)+x $.


And let's pretend that the only thing we know is that $1 : \op{Int}$, 
but we don't know the type of $+$. 
$\W$ can deal with this situation and infer that $e$ has type $Int \ar Int$ and
that $+$ has type $Int \ar Int \ar Int$. This can be achieved by calling $\W$ with
typing context $\Gamma = \{ 1 : \op{Int}, + : \alpha \}$, 
where $\alpha$ is a \textit{type variable}.

But if the only result of the $\W(\Gamma,e)$ is the type $\tau$ of $e$, 
how we get the information about the inferred type of $+$? 
Well, $\W$ actually returns a pair $(S, \tau)$, where $S$ is a substitution
containing the rest of the inferred type information. 
More specifically, $S(\alpha) = Int \ar Int \ar Int$.  

Now we can state the behavior of the $\W$ algorithm more formally:

~

Given context $\Gamma$ and expression $e$ the Hindley-Milner algorithm $\W$ 
is looking for the substitution $S$ and type $\tau$ such that: 
$$ S(\Gamma) \vdash e : \tau $$
If there are no such $S$ and $\tau$, then the $\W$ algorithm fails.
But if there are any, $\W$ finds the most general $S$ a $\tau$.


\begin{align*}
\W(\Gamma, e) = &
\begin{cases*}
  (S, \tau) 
  & \textbf{if} there is any $\SPr$ and $\tauPr$ such that $S^\prime(\Gamma) \vdash e : \tauPr$  \\
  \bot & \textbf{otherwise}
\end{cases*}\\
\end{align*}




\subsection{Definition of W algorithm}

Here we present a recursive definition of $\W$ algorithm based on case analysis of all possible patterns that program expression $e$ may have 
(i.e. $e$ may be a \textit{variable}, an \textit{application}, an \textit{abstraction}, or a \textit{let-expression}). 

~

\red{need to comment the need for fresh type variables $\beta$s}

\red{need to comment that when sub call fail, then also the calling computation fails}

~

\textbf{(1)} Expression $e$ is a \textit{variable}; $e = x$:

\begin{align*}
\W(\Gamma, x) \defi ~ &
\begin{cases*}
  (\{\}, R(\tauPr) ) 
  & \textbf{if} $(x : \forall \alpha_1 \dots \alpha_n.\tauPr) \in \Gamma$  \\
  \bot & \textbf{otherwise}
\end{cases*}\\
\where & R = \{\alpha_1 \mapsto \beta_1, \dots, \alpha_n \mapsto \beta_n\} \\
\end{align*}


\textbf{(2)} Expression $e$ is an \textit{application}; $e = (e_1~e_2)$:

\begin{align*}
\W(\Gamma, (e_1~e_2)) \defi ~ & 
\begin{cases*}
  (R \circ S_2 \circ S_1, R(\beta) ) & \textbf{if} $R \neq \bot$ \\
  \bot & \textbf{if} $R = \bot$
\end{cases*}\\
\where & (S_1, \tau_1) = \W(\Gamma, e_1), \\
       & (S_2, \tau_2) = \W(S_1(\Gamma), e_2), \\
       & R = \Mgu( S_2(\tau_1), \tau_2 \ar \beta ).\\
\end{align*}


\textbf{(3)} Expression $e$ is an \textit{abstraction}; $e = \lambda x . e_1$:

\begin{align*}
\W(\Gamma, \lambda x .e_1) \defi ~ & (S_1, S_1(\beta) \ar \tau_1 ) \\
\where & (S_1, \tau_1) = \W(\Gamma_x, x : \beta ~;~ e_1). \\
\end{align*}



\textbf{(4)} Expression $e$ is a \textit{let-expression}; $e = (\letin{x}{e_1}{e_2})$:

\begin{align*}
\W(\Gamma, \letin{x}{e_1}{e_2}) \defi ~ & (S_2 \circ S_1, \tau_2) \\
\where & (S_1, \tau_1) = \W(\Gamma, e_1), \\
       & (S_2, \tau_2) = \W(S_1(\Gamma_x),x:\overline{(S_1(\Gamma))}(\tau_1); e_2). \\
\end{align*}

\subsection{Example run of W algorithm}

We demonstrate $\W$ algorithm on simple example which contains all four possible forms of expressions as sub-expressions:
$$\letin{x}{\lambda x . x}{f~f}$$

All the contained program variables
($f$ and $x$) are locally defined variables, so we don't need to provide any further type
information, therefore we call $\W$ with an empty typing context $\Gamma = \emptyset$. 

$$\W(\emptyset, \letin{f}{\lambda x . x}{f~f})$$

The expression matches the case \textbf{(4)}:
\begin{align*}
\W(\emptyset, \letin{f}{\lambda x . x}{f~f}) \defi ~ & (S_2 \circ S_1, \tau_2) \\
\where & (S_1, \tau_1) = \W(\emptyset, \lambda x . x), \\
       & (S_2, \tau_2) = \W(S_1(\emptyset_f),f:\overline{(S_1(\emptyset))}(\tau_1); f~f).
\end{align*}

So we need to first compute the type (and substitution) of the $e_1 = \lambda x . x$, matching the case \textbf{(3)}:
\begin{align*}
\W(\emptyset, \lambda x .x) \defi ~ & (S_1, S_1(\beta_1) \ar \tau_1 ) \\
\where & (S_1, \tau_1) = \W(\{x : \beta_1 \}~,~ x).
\end{align*}

Finally we get to the first variable (case \textbf{(1)}), thus we will get our first result.
\begin{align*}
\W(\{x : \beta_1 \}~,~ x) \defi ~ & ( \{\}, R(\beta_1) ) \where  R = \{\} \\
                              = ~ & ( \{\}, \beta_1 )
\end{align*}

Because $x$ has type $\beta_1$ in the context $\{x : \beta_1\}$, and $\beta_1$ has no universally quantified prefix head, the substitution $R$ is empty, therefore identity. With this information we can get back to computation of $\W(\emptyset, \lambda x .x)$ and finish it. 
\begin{align*}
\W(\emptyset, \lambda x . x) \defi ~ & (S_1, S_1(\beta_1) \ar \tau_1 ) \where (S_1, \tau_1) = ( \{\}, \beta_1 ) \\
 = ~ & (\{\}, \{\}(\beta_1) \ar \beta_1 ) = (\{\}, \beta_1 \ar \beta_1 )
\end{align*}

By this we have finished the first recursive call in computation of \\
$\W(\emptyset, \letin{f}{\lambda x . x}{f~f})$. So we can compute the second recursive call:
\begin{align*}
& \W(S_1(\emptyset_f),f:\overline{(S_1(\emptyset))}(\tau_1); f~f) \where (S_1, \tau_1) = (\{\}, \beta_1 \ar \beta_1 ) \\
= & \W(\{\}(\emptyset_f),f:\overline{(\{\}(\emptyset))}(\beta_1 \ar \beta_1); f~f) \\
= & \W(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}; f~f)
\end{align*}

Now wee need to compute the type of expression $(f~f)$ which is an application (case \textbf{(2)}) from typing context $\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}$, specifying that $f$ has type of the \textit{polymorphic} identity. 
\begin{align*}
\W(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}; f~f) \defi ~ & 
(R \circ S_2 \circ S_1, R(\beta_?) ) \\
\where & (S_1, \tau_1) = \W(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}, f), \\
       & (S_2, \tau_2) = \W(S_1(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}), f), \\
       & R = \Mgu( S_2(\tau_1), \tau_2 \ar \beta_? ).\\
\end{align*}

You can see $\beta_?$ which is used to signify that it is not obvious what index the new fresh variable will have, since the two recursive calls to $\W$ may produce some new fresh variables before $\beta_?$ is introduced. Actually both calls produce one new type variable, thus $\beta_?$ will be $\beta_4$, as we will see.
\begin{align*}
\W(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}, f) \defi ~ & (\{\}, R(\beta_1 \ar \beta_1) ) 
~ \where R = \{\beta_1 \mapsto \beta_2\} \\
= ~ &  (\{\}, \beta_2 \ar \beta_2)
\end{align*}

Now we can continue with the second call:
\begin{align*}
\W(\{\}(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}), f) \defi ~ & (\{\}, R(\beta_1 \ar \beta_1) ) 
~ \where R = \{\beta_1 \mapsto \beta_3\} \\
= ~ &  (\{\}, \beta_3 \ar \beta_3)
\end{align*}

And finally we compute the \textit{most general unification} $R$:
\begin{align*}
R & = \Mgu(\beta_2 \ar \beta_2, (\beta_3 \ar \beta_3) \ar \beta_4 ) \\
  & = \{ \beta_2 \mapsto (\beta_3 \ar \beta_3),~ \beta_4 \mapsto (\beta_3 \ar \beta_3) \}
\end{align*}

One can see that R really unifies $\beta_2 \ar \beta_2$ and $(\beta_3 \ar \beta_3) \ar \beta_4$,
because $R(\beta_2 \ar \beta_2) = (\beta_3 \ar \beta_3) \ar (\beta_3 \ar \beta_3) = R((\beta_3 \ar \beta_3) \ar \beta_4)$. Now the computation of $\W(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}; f~f)$ can be finished:
\begin{align*}
\W(\{f:\forall \beta_1 . \beta_1 \ar \beta_1 \}; f~f) 
\defi ~ & (R \circ S_2 \circ S_1, R(\beta_4) ) \\
    = ~ & (\{ \beta_2 \mapsto (\beta_3 \ar \beta_3), \beta_4 \mapsto (\beta_3 \ar \beta_3) \} \circ \{\} \circ \{\},~ \beta_3 \ar \beta_3 )\\ 
    = ~ & (\{ \beta_2 \mapsto (\beta_3 \ar \beta_3), \beta_4 \mapsto (\beta_3 \ar \beta_3) \}, ~ \beta_3 \ar \beta_3 ) 
\end{align*}

Now we can compute the final result:
\begin{align*}
\W(\emptyset, \letin{f}{\lambda x . x}{f~f}) = ~ & (S_2 \circ S_1, \tau_2) \\
\where & (S_1, \tau_1) = (\{\}, \beta_1 \ar \beta_1 ), \\
       & (S_2, \tau_2) = (\{ \beta_2 \mapsto (\beta_3 \ar \beta_3), \beta_4 \mapsto (\beta_3 \ar \beta_3) \}, ~ \beta_3 \ar \beta_3 ).
\end{align*}

And therefore:
\begin{align*}
\W(\emptyset, \letin{f}{\lambda x . x}{f~f}) = ~ & (\{ \beta_2 \mapsto (\beta_3 \ar \beta_3), \beta_4 \mapsto (\beta_3 \ar \beta_3) \},~ \beta_3 \ar \beta_3)
\end{align*}

We get an unsurprising result:
$$\emptyset \vdash (\letin{f}{\lambda x . x}{f~f}) : \beta_3 \ar \beta_3$$
~

~

\red{todo}





\subsection{Correctness and completeness of W}

~

\subsubsection{Correctness of W}

If $\W(\Gamma, e) = (S, \tau)$, then exist derivation of the judgment $S(\Gamma) \vdash e : \tau$.

~

\subsubsection{Completeness of W}

Let $\Gamma$ be a context and $e$ a program expression,
and let $\SPr$ be a substitution and $\tauPr$ a type such that:
$ \SPr(\Gamma) \vdash e : \tauPr $, 
then:

(1) $\W(\Gamma,e)$ succeeds (i.e. $\W(\Gamma,e) \neq \bot$), 
let $\W(\Gamma,e) = (S, \tau)$,

(2) there is a substitution $R$ such that $\SPr = R \circ S$ 
and $R\overline{(S(\Gamma))}(\tau) \sqsupseteq \tauPr$. 

~ 

The correctness theorem states that if $\W$ finds a solution, then the solution is correct.
The first part of the completeness theorem, states that if there is a solution, then $\W$ finds one. And the second part formally states that the found solution $(S,\tau)$ is the most general one, by comparing it with an arbitrary solution $(\SPr,\tauPr)$. The substitution $R$ acts as a witness of the fact that we can obtain $\SPr$ by making $S$ more specific ($\SPr = R \circ S$).  

\red{Než bude možno vysvětlit druhou část dvojky, je třeba zavést ten closure overline někde vejš}

~

\section{Unification algorithm}
\red{todo: some comment}

\Pseudokod{Algorithm finding the most general unification.}
{\textbf{MGU}($\tau_1$, $\tau_2$)}{
	
	$result = \{\}$ \;
	$agenda \la [(\tau_1$, $\tau_2)]$ \;	
	$isOK \la True$ \;

	\;	
	
	\While {agenda not empty $\wedge$ isOK}{
		$(\tau_a, \tau_b) \la agenda.removeFirst()$ \;
		$isOK = \textbf{process}(\tau_a, \tau_b, agenda, result)$			
	}
	\;
	
	\If {$isOK$} {
		\Return $result$
	} \Else {
		\Return $\bot$				
	}
	
}{mguAlg}

\Pseudokod{Processes one type pair.}
{\textbf{process}($\tau_1$, $\tau_2, agenda, result$)}{
	\;
	\If {$\tau_1$ and $\tau_2$ are the same \textbf{TypeVar}} {
		\Return $True$
	} \;

	\If {$\tau_1$ and $\tau_2$ are the same \textbf{TypeSym}} {
		\Return $True$
	} \;

	\If {$\tau_1$ and $\tau_2$ are both \textbf{TypeTerm} with the same length} {
		$agenda.addAll(zip(\tau_1.args(), \tau_2.args()))$ \;
		\Return $True$
	} \;
	
	\If {$\tau_1$ is a \textbf{TypeVar}} {
		\Return $\textbf{processTypeVar}(\tau_1$, $\tau_2, agenda, result)$
	} \;
	
	\If {$\tau_2$ is a \textbf{TypeVar}} {
		\Return $\textbf{processTypeVar}(\tau_2$, $\tau_1, agenda, result)$
	} \;	
	
	\Return $False$
	
}{mguAlgProcess}

\Pseudokod{Processes one $var \mapsto type$ binding.}
{\textbf{processTypeVar}($var, type, agenda, result$)}{
	\;
	
	\If {$type$ contains $var$} {
		\Return $False$
	} \;

	$S \la \{var \mapsto type \}$\;\;

	\For {$entry$ in $result$} {
		$(v \mapsto \tau) \la entry$ \;
		$entry.set_{\tau}( S(\tau) )$
	} \;

	\For {$entry$ in $agenda$} {
		$(\tau_1, \tau_2) \la entry$ \;
		$entry.set_{\tau_1}( S(\tau_1) )$ \;
		$entry.set_{\tau_2}( S(\tau_2) )$
	} \;

	
	$result.add(var \mapsto type)$ \;\;
	
	\Return $True$
	
}{mguAlgProcessTypeVar}
















\backmatter
\end{document}

